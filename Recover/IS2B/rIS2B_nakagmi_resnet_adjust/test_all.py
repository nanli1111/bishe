import os
import math
import torch
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from matplotlib import rcParams
import csv

# === å¼•å…¥é¡¹ç›®æ¨¡å— ===
from model.resnet_pro import DilatedTimeResNet1D  # ç¡®ä¿è¿™é‡Œå¯¼å…¥çš„æ˜¯ä½ çš„æ¨¡å‹ç±»
from IS2B_x_pre import IS2B
from dataset.dataset import QPSKDataset
from test_fig_x_pre import add_awgn_noise_torch

# ä¸­æ–‡å­—ä½“è®¾ç½®
rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']
rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. è¾…åŠ©å‡½æ•°
# ==========================================
def decision_making(symbols):
    """QPSK ç¡¬åˆ¤å†³"""
    real_part = np.real(symbols)
    imag_part = np.imag(symbols)
    bits = np.zeros((len(symbols), 2), dtype=int)
    bits[(real_part > 0) & (imag_part > 0)] = (0, 0)
    bits[(real_part < 0) & (imag_part > 0)] = (0, 1)
    bits[(real_part < 0) & (imag_part < 0)] = (1, 1)
    bits[(real_part > 0) & (imag_part < 0)] = (1, 0)
    return bits

def calculate_ber(labels_true, labels_pred):
    labels_pred = labels_pred.astype(int)
    err_i = np.sum(labels_true[:, 0] != labels_pred[:, 0])
    err_q = np.sum(labels_true[:, 1] != labels_pred[:, 1])
    ber = (err_i + err_q) / (len(labels_true) * 2)
    return ber

def IS2B_restore_symbol_hybrid(model, device, n_steps, snr_db_sample, rx_clean, h_np, batch_size=256, guidance_scale=1.0):
    """
    æ‰§è¡Œ IS2B æ··åˆæ¢å¤ï¼šOne-Step Anchor + Rectified Flow Refinement
    """
    n, c, L = rx_clean.shape
    
    # ä¸´æ—¶æ„å»º IS2B å®ä¾‹
    is2b_instance = IS2B(model, n_steps=n_steps, device=device)

    rx_clean_tensor = torch.from_numpy(rx_clean).float().to(device)
    y_all = add_awgn_noise_torch(rx_clean_tensor, snr_db_sample)
    
    if h_np.ndim == 2:
        h_expanded = h_np[:, :, np.newaxis]
        h_expanded = np.repeat(h_expanded, L, axis=-1)
    else:
        h_expanded = h_np
    h_all = torch.from_numpy(h_expanded).float().to(device)

    recovered = []
    model.eval()

    with torch.no_grad():
        for start in tqdm(range(0, n, batch_size), desc=f"SNR={snr_db_sample:.1f}dB"):
            end = min(start + batch_size, n)
            
            y_batch = y_all[start:end]
            h_batch = h_all[start:end]
            current_batch_size = y_batch.shape[0]
            
            # Step A: Anchor (One-Step)
            net_input_os = torch.cat([y_batch, h_batch], dim=1)
            t_max = torch.full((current_batch_size,), n_steps - 1, device=device, dtype=torch.long)
            anchor_x = model(net_input_os, t_max)
            
            # Step B: Rectified Flow (Hybrid)
            x_rec = is2b_instance.sample(
                y=y_batch,
                h=h_batch,
                guidance_scale=guidance_scale,
                stop_t=0.0,      # ä¿æŒæˆªæ–­ç­–ç•¥
                anchor=anchor_x  # ä¼ å…¥ Anchor
            )
            recovered.append(x_rec.cpu().numpy())

    recovered = np.concatenate(recovered, axis=0)
    mid = L // 2
    sym_i = recovered[:, 0, mid]
    sym_q = recovered[:, 1, mid]
    symbols = sym_i + 1j * sym_q
    
    return symbols

# ==========================================
# 2. è¯„ä¼°æ ¸å¿ƒå‡½æ•° (åŠ¨æ€æ¨¡å‹ç»“æ„)
# ==========================================
def evaluate_single_model(name, ckpt_path, hidden_dim, num_blocks, device, test_data_tuple, snr_range, sps, batch_size):
    """
    è¯„ä¼°å•ä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œæ”¯æŒåŠ¨æ€ä¼ å…¥ hidden_dim å’Œ num_blocks
    """
    print(f"\nğŸš€ Evaluating Model: {name}")
    print(f"   Path: {ckpt_path}")
    print(f"   Config: hidden_dim={hidden_dim}, num_blocks={num_blocks}")
    
    # 1. åŠ¨æ€å®ä¾‹åŒ–æ¨¡å‹
    # time_emb_dim é€šå¸¸ä¸ hidden_dim ä¸€è‡´æˆ–å›ºå®šï¼Œè¿™é‡Œå‡è®¾ä¸ hidden_dim ä¸€è‡´ä»¥ä¿æŒçµæ´»æ€§
    model = DilatedTimeResNet1D(
        in_channels=4, 
        out_channels=2, 
        hidden_dim=hidden_dim,   
        num_blocks=num_blocks,    
        time_emb_dim=hidden_dim # æˆ–è€…å›ºå®šä¸º 128ï¼Œçœ‹ä½ è®­ç»ƒæ—¶çš„è®¾ç½®
    ).to(device)

    if os.path.exists(ckpt_path):
        try:
            model.load_state_dict(torch.load(ckpt_path, map_location=device))
        except RuntimeError as e:
            print(f"âŒ Error loading state dict: {e}")
            print("   (å¯èƒ½æ˜¯æ¨¡å‹ç»“æ„å‚æ•°ä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥ hidden_dim å’Œ num_blocks)")
            return None
    else:
        print(f"âŒ Error: Checkpoint not found: {ckpt_path}")
        return None

    # è§£åŒ…æ•°æ®
    rx_clean, h_np, labels_iq = test_data_tuple
    
    # 2. è¿è¡Œæµ‹è¯•
    bers = []
    n_steps = 20 # å‡è®¾è®­ç»ƒæ—¶éƒ½æ˜¯20æ­¥
    
    for snr_db in snr_range:
        snr_db_sample = snr_db - 10 * math.log10(sps) + 10 * math.log10(2)
        
        symbols = IS2B_restore_symbol_hybrid(
            model=model,
            device=device,
            n_steps=n_steps,
            snr_db_sample=snr_db_sample,
            rx_clean=rx_clean,
            h_np=h_np,
            batch_size=batch_size,
            guidance_scale=1.0
        )
        
        labels_pred = decision_making(symbols)
        ber = calculate_ber(labels_iq, labels_pred)
        bers.append(ber)
        print(f"   SNR={snr_db}dB | BER={ber:.6e}") # å¦‚æœä¸æƒ³åˆ·å±å¯ä»¥æ³¨é‡Šæ‰
        
    return bers

# ==========================================
# 3. ç»˜å›¾å‡½æ•°
# ==========================================
def plot_multi_model_ber(results_dict, ref_resnet, ref_baseline, snr_range, save_path):
    plt.figure(figsize=(12, 8))
    snr_array = np.array(snr_range)
    
    # 1. ç»˜åˆ¶å„ä¸ªæµ‹è¯•æ¨¡å‹çš„æ›²çº¿
    markers = ['o-', 's-', 'D-', '^-', 'v-', 'x-', '*-']
    for i, (name, bers) in enumerate(results_dict.items()):
        marker = markers[i % len(markers)]
        plt.semilogy(snr_array, bers, marker, linewidth=2, label=name)
    
    # 2. ç»˜åˆ¶å‚è€ƒçº¿ (ResNet)
    if len(ref_resnet) > 0:
        limit = min(len(snr_array), len(ref_resnet))
        plt.semilogy(snr_array[:limit], ref_resnet[:limit], '--', color='gray', alpha=0.6, label='Ref: ResNet (Base)')

    # 3. ç»˜åˆ¶å‚è€ƒçº¿ (Baseline MMSE)
    if len(ref_baseline) > 0:
        limit = min(len(snr_array), len(ref_baseline))
        plt.semilogy(snr_array[:limit], ref_baseline[:limit], '-.', color='black', alpha=0.6, label='Ref: MMSE')

    plt.grid(True, which='both', linestyle='--', alpha=0.5)
    plt.xlabel('SNR per symbol (dB)')
    plt.ylabel('BER')
    plt.title('Multi-Model BER Comparison (Hybrid Decoding)')
    plt.legend()
    plt.ylim(1e-6, 1.0) 
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=300)
    print(f"âœ… ç»˜å›¾å®Œæˆ: {save_path}")
    plt.close()

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 4096 
    sps = 16 
    
    # === é…ç½®ï¼šæ¨¡å‹åˆ—è¡¨ ===
    # æ ¼å¼ï¼š(å›¾ä¾‹åç§°, æƒé‡è·¯å¾„, hidden_dim, num_blocks)
    models_to_test = [
        # æ¨¡å‹ 1: åŸç‰ˆ (128, 12)
        ("Base (128-12)", 
         r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_pro_20.pth", 
         128, 12),
         
        # æ¨¡å‹ 2
        ("L1 Loss (0.5)", 
         r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_pro_0.5L1_20.pth", 
         128, 12),
         
        # æ¨¡å‹ 3
        ("L1 Loss (0.7)", 
         r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_pro_0.7L1_20.pth", 
         128, 12),

        # æ¨¡å‹ 4
        ("crum Loss", 
          r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_pro_crum_20.pth",
          128, 12),
        # æ¨¡å‹ 5
        ("Scope Loss", 
         r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_pro_scope_20.pth",
          128, 12),
          
        # æ¨¡å‹ 6
        ("Cosine LR",
            r"F:\LJN\bishe\bishe\IS2B\rIS2B_nakagmi_resnet_adjust\results\best_model_IS2B_resnet_cos.pth",
            256, 8),

    ]
    
    # ç»“æœä¿å­˜è·¯å¾„
    save_dir = r'IS2B/rIS2B_nakagmi_resnet_adjust/comparison_results'
    baseline_csv_path = 'IS2B/rIS2B_nakagmi_resnet_adjust/ber_results/ber_curve_resnet_values.csv'

    # === 1. ç»Ÿä¸€åŠ è½½æ•°æ® (åªåŠ è½½ä¸€æ¬¡) ===
    print("Loading Test Data...")
    test_start, test_end = 400000, 500000
    test_data = QPSKDataset(test_start, test_end)
    rx_clean = test_data.y   
    h_np = test_data.z       
    
    label_path = r'F:\LJN\bishe\bishe\data\nakagmi_data\labels.npy'
    label_all = np.load(label_path)
    label_seg = label_all[test_start:test_end]
    map_label = {0: (0, 0), 1: (0, 1), 2: (1, 1), 3: (1, 0)}
    labels_iq = np.array([map_label[int(v)] for v in label_seg], dtype=int)
    
    data_tuple = (rx_clean, h_np, labels_iq)

    # === 2. æ‰¹é‡æµ‹è¯• ===
    snr_range = np.arange(0, 19, 1)
    results_dict = {} 
    
    # è§£åŒ…ç”±4ä¸ªå…ƒç´ ç»„æˆçš„å…ƒç»„
    for name, path, h_dim, n_blk in models_to_test:
        bers = evaluate_single_model(
            name=name, 
            ckpt_path=path, 
            hidden_dim=h_dim,   # ä¼ å…¥ç‰¹å®šçš„å®½åº¦
            num_blocks=n_blk,   # ä¼ å…¥ç‰¹å®šçš„æ·±åº¦
            device=device, 
            test_data_tuple=data_tuple, 
            snr_range=snr_range, 
            sps=sps, 
            batch_size=batch_size
        )
        if bers is not None:
            results_dict[name] = bers

    # === 3. è¯»å–å‚è€ƒæ•°æ® ===
    ref_resnet_bers = []
    ref_baseline_bers = []
    if os.path.exists(baseline_csv_path):
        try:
            with open(baseline_csv_path, 'r', newline='') as f:
                reader = csv.DictReader(f)
                csv_resnet_map = {}
                csv_baseline_map = {}
                for row in reader:
                    try:
                        s = round(float(row['snr_db']), 1)
                        csv_resnet_map[s] = float(row['resnet_ber'])
                        csv_baseline_map[s] = float(row['baseline_ber'])
                    except ValueError: continue

                for snr in snr_range:
                    k = round(float(snr), 1)
                    if k in csv_resnet_map: ref_resnet_bers.append(csv_resnet_map[k])
                    if k in csv_baseline_map: ref_baseline_bers.append(csv_baseline_map[k])
        except Exception as e:
            print(f"Error reading baseline: {e}")

    # === 4. ç»˜å›¾ä¸ä¿å­˜ ===
    plot_path = os.path.join(save_dir, 'multi_model_arch_comparison.png')
    plot_multi_model_ber(results_dict, ref_resnet_bers, ref_baseline_bers, snr_range, plot_path)
    
    csv_save_path = os.path.join(save_dir, 'multi_model_arch_data.csv')
    with open(csv_save_path, 'w', newline='') as f:
        writer = csv.writer(f)
        header = ['snr_db'] + list(results_dict.keys())
        writer.writerow(header)
        for i, snr in enumerate(snr_range):
            row = [snr]
            for name in results_dict.keys():
                row.append(f"{results_dict[name][i]:.6e}")
            writer.writerow(row)
    print(f"âœ… æ•°æ®æ±‡æ€» CSV å·²ä¿å­˜: {csv_save_path}") 