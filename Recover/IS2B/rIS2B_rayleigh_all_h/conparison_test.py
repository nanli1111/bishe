import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import math
import csv
from torch.utils.data import DataLoader

# === å¼•å…¥é¡¹ç›®æ¨¡å— ===
from model.unet import build_network
from dataset.dataset import QPSKDataset
from test_fig_x_pre import add_awgn_noise_torch

# === 1. åˆ¤å†³å‡½æ•° ===
def decision_making(symbols_complex):
    """
    QPSK ç¡¬åˆ¤å†³
    è¾“å…¥: Numpy Complex Array shape (B,)
    è¾“å‡º: Numpy Int Array shape (B, 2)
    """
    real_part = np.real(symbols_complex)
    imag_part = np.imag(symbols_complex)
    
    bits = np.zeros((len(symbols_complex), 2), dtype=int)
    # 00: (+, +), 01: (-, +), 11: (-, -), 10: (+, -)
    bits[(real_part > 0) & (imag_part > 0)] = (0, 0)
    bits[(real_part < 0) & (imag_part > 0)] = (0, 1)
    bits[(real_part < 0) & (imag_part < 0)] = (1, 1)
    bits[(real_part > 0) & (imag_part < 0)] = (1, 0)
    return bits

# === 2. æµ‹è¯•ä¸»å‡½æ•° ===
def test_supervised_model(model, test_loader, all_labels_iq, 
                          snr_range, device, sps, save_dir):
    
    model.eval()
    ber_results = []
    
    # è·å–åºåˆ—é•¿åº¦ L (å‡è®¾æ‰€æœ‰æ ·æœ¬é•¿åº¦ä¸€è‡´)
    # ä» loader å–ä¸€ä¸ªæ ·æœ¬çœ‹å½¢çŠ¶
    dummy_x, _, _ = next(iter(test_loader))
    L = dummy_x.shape[2]
    mid_point = L // 2
    
    print(f"ğŸš€ å¼€å§‹æµ‹è¯• (Mode: Supervised Direct Pred | Sampling: Index {mid_point})")
    
    for snr_db in snr_range:
        # æ¢ç®— SNR
        snr_sample = snr_db - 10 * math.log10(sps)
        
        total_err = 0
        total_bits = 0
        
        # éå†æµ‹è¯•é›†
        # ä½¿ç”¨ enumerate é…åˆ batch_size æ¥å®šä½å¯¹åº”çš„æ ‡ç­¾
        for batch_idx, (clean_x, faded_y, h_est) in enumerate(tqdm(test_loader, desc=f"SNR {snr_db}dB", leave=False)):
            
            clean_x = clean_x.to(device).float()
            faded_y = faded_y.to(device).float()
            h_est = h_est.to(device).float()
            
            batch_size = clean_x.shape[0]
            seq_len = clean_x.shape[2]

            # 1. æ‰©å±• h
            if h_est.dim() == 2:
                h_expanded = h_est.unsqueeze(-1).repeat(1, 1, seq_len)
            else:
                h_expanded = h_est

            # 2. åŠ å™ª
            noisy_y = add_awgn_noise_torch(faded_y, snr_sample)

            # 3. æ„é€ è¾“å…¥ (çº¯ç›‘ç£æ¨¡å‹ t æ’ä¸º 0)
            t_dummy = torch.zeros(batch_size, device=device, dtype=torch.long)
            net_input = torch.cat([noisy_y, h_expanded], dim=1)

            # 4. é¢„æµ‹
            with torch.no_grad():
                pred_x = model(net_input, t_dummy) # Output: [B, 2, L]
            
            # 5. ä¸­å¿ƒé‡‡æ · & è½¬å¤æ•°
            pred_np = pred_x.cpu().numpy()
            pred_i = pred_np[:, 0, mid_point]
            pred_q = pred_np[:, 1, mid_point]
            pred_symbols = pred_i + 1j * pred_q # shape (B,)
            
            # 6. åˆ¤å†³
            pred_bits = decision_making(pred_symbols) # shape (B, 2)
            
            # 7. è·å–å¯¹åº”æ ‡ç­¾
            # è®¡ç®—å½“å‰ batch åœ¨æ€»æ ‡ç­¾ä¸­çš„ç´¢å¼•èŒƒå›´
            start_idx = batch_idx * test_loader.batch_size
            end_idx = start_idx + batch_size
            
            # é˜²æ­¢æœ€åä¸è¶³ä¸€ä¸ª batch å¯¼è‡´ç´¢å¼•è¶Šç•Œ
            current_labels = all_labels_iq[start_idx : end_idx]
            
            # 8. è®¡ç®—è¯¯ç 
            # current_labels æ˜¯ (B, 2)
            err_i = np.sum(current_labels[:, 0] != pred_bits[:, 0])
            err_q = np.sum(current_labels[:, 1] != pred_bits[:, 1])
            
            total_err += (err_i + err_q)
            total_bits += (batch_size * 2)
            
        # è®¡ç®—å½“å‰ SNR ä¸‹çš„æ€» BER
        avg_ber = total_err / total_bits
        ber_results.append(avg_ber)
        print(f"SNR: {snr_db}dB | BER: {avg_ber:.6e}")
        
    return ber_results

# === 3. ä¿å­˜ä¸ç»˜å›¾ ===
def save_and_plot(snr_range, ber_list, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    csv_path = os.path.join(save_dir, 'ber_results_supervised.csv')
    png_path = os.path.join(save_dir, 'ber_curve_supervised.png')
    
    # ä¿å­˜ CSV
    with open(csv_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['snr_db', 'ber'])
        for s, b in zip(snr_range, ber_list):
            writer.writerow([s, f"{b:.6e}"])
    print(f"æ•°æ®å·²ä¿å­˜è‡³: {csv_path}")
    
    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.semilogy(snr_range, ber_list, 'o-', color='red', label='Supervised Model (UNet)')
    plt.grid(True, which='both', linestyle='--', alpha=0.7)
    plt.xlabel('SNR (dB)')
    plt.ylabel('BER')
    plt.title('BER Performance: Supervised Learning')
    plt.legend()
    plt.savefig(png_path)
    print(f"æ›²çº¿å›¾å·²ä¿å­˜è‡³: {png_path}")

if __name__ == "__main__":
    # === é…ç½® ===
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    n_steps = 100
    batch_size = 4096 # æµ‹è¯•æ—¶å¯ä»¥å¼€å¤§ä¸€ç‚¹
    sps = 16 
    
    # æƒé‡è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„)
    model_path = r'IS2B/rIS2B_rayleigh_all_h/results/best_model_supervised.pth'
    
    # ç»“æœä¿å­˜ç›®å½•
    save_dir = r'ber_results/supervised_test'
    
    # æ•°æ®èŒƒå›´ (æµ‹è¯•é›†: 400000 ~ 500000)
    test_start = 400000
    test_end = 500000
    
    # æ ‡ç­¾æ–‡ä»¶è·¯å¾„
    label_file_path = r'F:\LJN\bishe\bishe\data\rayleigh_data_all_h\labels.npy'

    # === 1. å‡†å¤‡æ•°æ® ===
    print("Loading Test Data...")
    # å…³é”®ï¼šshuffle=False ä¿è¯é¡ºåºï¼Œnum_workers=0 é˜²æ­¢å¤šè¿›ç¨‹ä¹±åº(è™½ç„¶Falseé€šå¸¸æ²¡äº‹ï¼Œä½†0æœ€ç¨³)
    test_dataset = QPSKDataset(test_start, test_end)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    print("Loading Labels...")
    # è¯»å–æ ‡ç­¾å¹¶æˆªå–å¯¹åº”éƒ¨åˆ†
    all_labels_raw = np.load(label_file_path)
    test_labels_raw = all_labels_raw[test_start:test_end]
    
    # æ˜ å°„ä¸ºæ¯”ç‰¹
    map_label = {0: (0, 0), 1: (0, 1), 2: (1, 1), 3: (1, 0)}
    test_labels_iq = np.array([map_label[int(v)] for v in test_labels_raw], dtype=int)
    
    print(f"Test Data Size: {len(test_dataset)}")
    print(f"Test Labels Size: {test_labels_iq.shape}")
    assert len(test_dataset) == test_labels_iq.shape[0], "æ•°æ®é‡ä¸æ ‡ç­¾é‡ä¸åŒ¹é…ï¼"

    # === 2. åŠ è½½æ¨¡å‹ ===
    net_cfg = {
        'type': 'UNet',
        'channels': [32, 64, 128, 256], 
        'pe_dim': 128,
        'in_channels': 4,  
        'out_channels': 2 
    }
    print(f"Loading Model from {model_path}...")
    model = build_network(net_cfg, n_steps).to(device)
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("Model Loaded Successfully.")
    else:
        raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

    # === 3. è¿è¡Œæµ‹è¯• ===
    snr_range = np.arange(2, 19, 1) # 2 ~ 18 dB
    
    ber_list = test_supervised_model(
        model=model,
        test_loader=test_loader,
        all_labels_iq=test_labels_iq,
        snr_range=snr_range,
        device=device,
        sps=sps,
        save_dir=save_dir
    )

    # === 4. ä¿å­˜ç»“æœ ===
    save_and_plot(snr_range, ber_list, save_dir)