import os
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import math
import csv
from torch.utils.data import DataLoader

# === å¼•å…¥é¡¹ç›®æ¨¡å— ===
from dataset.dataset import QPSKDataset
from test_fig_x_pre import add_awgn_noise_torch

# ==========================================
# 1. æ¨¡å‹å®šä¹‰ (å¿…é¡»ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´)
# ==========================================
class ResBlock1D(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm1d(channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm1d(channels)

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out += residual
        out = self.relu(out)
        return out

class SimpleResNet1D(nn.Module):
    def __init__(self, in_channels=4, out_channels=2, hidden_dim=64, num_blocks=6):
        super().__init__()
        self.entry = nn.Sequential(
            nn.Conv1d(in_channels, hidden_dim, kernel_size=3, padding=1),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(inplace=True)
        )
        self.blocks = nn.ModuleList([
            ResBlock1D(hidden_dim) for _ in range(num_blocks)
        ])
        self.exit = nn.Conv1d(hidden_dim, out_channels, kernel_size=1)

    def forward(self, x, t=None):
        x = x.float()
        out = self.entry(x)
        for block in self.blocks:
            out = block(out)
        out = self.exit(out)
        return out

# ==========================================
# 2. åˆ¤å†³å‡½æ•°
# ==========================================
def decision_making(symbols_complex):
    """QPSK ç¡¬åˆ¤å†³"""
    real_part = np.real(symbols_complex)
    imag_part = np.imag(symbols_complex)
    
    bits = np.zeros((len(symbols_complex), 2), dtype=int)
    bits[(real_part > 0) & (imag_part > 0)] = (0, 0)
    bits[(real_part < 0) & (imag_part > 0)] = (0, 1)
    bits[(real_part < 0) & (imag_part < 0)] = (1, 1)
    bits[(real_part > 0) & (imag_part < 0)] = (1, 0)
    return bits

# ==========================================
# 3. æµ‹è¯•ä¸»é€»è¾‘
# ==========================================
def test_resnet_performance(model, test_loader, all_labels_iq, snr_range, device, sps):
    model.eval()
    ber_results = []
    
    # ç¡®å®šä¸­ç‚¹ä½ç½®
    dummy_x, _, _ = next(iter(test_loader))
    L = dummy_x.shape[2]
    mid_point = L // 2
    
    print(f"ğŸš€ å¼€å§‹æµ‹è¯• SimpleResNet1D (Sampling Index: {mid_point})...")
    
    for snr_db in snr_range:
        # æ¢ç®—é‡‡æ · SNR
        snr_sample = snr_db - 10 * math.log10(sps)
        
        total_err = 0
        total_bits = 0
        
        # éå†æµ‹è¯•é›†
        for batch_idx, (clean_x, faded_y, h_est) in enumerate(tqdm(test_loader, desc=f"SNR {snr_db}dB", leave=False)):
            
            clean_x = clean_x.to(device).float()
            faded_y = faded_y.to(device).float()
            h_est = h_est.to(device).float()
            
            batch_size = clean_x.shape[0]
            seq_len = clean_x.shape[2]

            # h æ‰©å±•
            if h_est.dim() == 2:
                h_expanded = h_est.unsqueeze(-1).repeat(1, 1, seq_len)
            else:
                h_expanded = h_est

            # åŠ å™ª
            noisy_y = add_awgn_noise_torch(faded_y, snr_sample)

            # æ„é€ è¾“å…¥
            net_input = torch.cat([noisy_y, h_expanded], dim=1)

            # é¢„æµ‹
            with torch.no_grad():
                pred_x = model(net_input, None) 
            
            # ä¸­å¿ƒé‡‡æ · & è½¬å¤æ•°
            pred_np = pred_x.cpu().numpy()
            pred_i = pred_np[:, 0, mid_point]
            pred_q = pred_np[:, 1, mid_point]
            pred_symbols = pred_i + 1j * pred_q 
            
            # åˆ¤å†³
            pred_bits = decision_making(pred_symbols) 
            
            # è·å–å¯¹åº”æ ‡ç­¾
            start_idx = batch_idx * test_loader.batch_size
            end_idx = start_idx + batch_size
            current_labels = all_labels_iq[start_idx : end_idx]
            
            # è®¡ç®—è¯¯ç 
            err_i = np.sum(current_labels[:, 0] != pred_bits[:, 0])
            err_q = np.sum(current_labels[:, 1] != pred_bits[:, 1])
            
            total_err += (err_i + err_q)
            total_bits += (batch_size * 2)
            
        avg_ber = total_err / total_bits
        ber_results.append(avg_ber)
        print(f"SNR: {snr_db}dB | BER: {avg_ber:.6e}")
        
    return ber_results

# ==========================================
# 4. ç»˜å›¾ä¸ä¿å­˜å‡½æ•° (å·²æ›´æ–°ï¼šæ”¯æŒ Baseline)
# ==========================================
def save_and_plot(snr_range, ber_list, ref_bers, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    csv_path = os.path.join(save_dir, 'ber_results_resnet.csv')
    png_path = os.path.join(save_dir, 'ber_curve_compare.png')
    
    # 1. ä¿å­˜æ¨¡å‹é¢„æµ‹ç»“æœåˆ° CSV
    with open(csv_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['snr_db', 'ber'])
        for s, b in zip(snr_range, ber_list):
            writer.writerow([s, f"{b:.6e}"])
    print(f"æ¨¡å‹ BER æ•°æ®å·²ä¿å­˜è‡³: {csv_path}")
    
    # 2. ç»˜å›¾
    plt.figure(figsize=(10, 6))
    
    # ç»˜åˆ¶æœ¬æ¨¡å‹æ›²çº¿
    plt.semilogy(snr_range, ber_list, 'o-', color='red', label='SimpleResNet1D (Supervised)')
    
    # ç»˜åˆ¶ Baseline (å¦‚æœå­˜åœ¨)
    if len(ref_bers) > 0:
        # æˆªæ–­ä»¥åŒ¹é…é•¿åº¦ (é˜²æ­¢ç»´åº¦ä¸ä¸€è‡´æŠ¥é”™)
        limit = min(len(snr_range), len(ref_bers))
        plt.semilogy(snr_range[:limit], ref_bers[:limit], 's--', color='blue', alpha=0.7, label='Baseline (MMSE)')
        print("å·²æ·»åŠ  Baseline æ›²çº¿ã€‚")
    else:
        print("æœªæ£€æµ‹åˆ° Baseline æ•°æ®ï¼Œä»…ç»˜åˆ¶æ¨¡å‹æ›²çº¿ã€‚")

    plt.grid(True, which='both', linestyle='--', alpha=0.7)
    plt.xlabel('SNR (dB)')
    plt.ylabel('BER')
    plt.title('BER Performance Comparison')
    plt.legend()
    plt.ylim(1e-6, 1.0) # é™åˆ¶Yè½´é˜²æ­¢æ˜¾ç¤ºå¼‚å¸¸
    plt.savefig(png_path)
    print(f"å¯¹æ¯”æ›²çº¿å›¾å·²ä¿å­˜è‡³: {png_path}")

# ==========================================
# 5. å…¥å£
# ==========================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 4096
    sps = 16 
    
    # === è·¯å¾„é…ç½® ===
    # æ¨¡å‹æƒé‡è·¯å¾„
    model_path = r'CNN/RESNET/results/best_model_resnet.pth' 
    # ç»“æœä¿å­˜ç›®å½•
    save_dir = r'CNN/RESNET/results'
    # æ ‡ç­¾æ–‡ä»¶
    label_file_path = r'F:\LJN\bishe\bishe\data\rayleigh_data_all_h\labels.npy'
    # åŸºå‡†æ–‡ä»¶è·¯å¾„ (Baseline)
    baseline_csv_path = r'CNN/RESNET/ber_results/baseline_ber.csv'

    # === 1. æ•°æ®å‡†å¤‡ ===
    test_start = 400000
    test_end = 500000

    print("Loading Test Data...")
    test_dataset = QPSKDataset(test_start, test_end)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    print("Loading Labels...")
    all_labels_raw = np.load(label_file_path)
    test_labels_raw = all_labels_raw[test_start:test_end]
    map_label = {0: (0, 0), 1: (0, 1), 2: (1, 1), 3: (1, 0)}
    test_labels_iq = np.array([map_label[int(v)] for v in test_labels_raw], dtype=int)
    
    # === 2. åŠ è½½æ¨¡å‹ ===
    print(f"Loading Model from {model_path}...")
    model = SimpleResNet1D(in_channels=4, out_channels=2, hidden_dim=64, num_blocks=6).to(device)
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("âœ… Model weights loaded.")
    else:
        raise FileNotFoundError(f"âŒ æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")

    # === 3. è¿è¡Œæ¨¡å‹æµ‹è¯• ===
    snr_range = np.arange(2, 19, 1) # 2 ~ 18 dB
    
    model_bers = test_resnet_performance(
        model=model,
        test_loader=test_loader,
        all_labels_iq=test_labels_iq,
        snr_range=snr_range,
        device=device,
        sps=sps
    )

    # === 4. è¯»å–åŸºå‡† BER (ä½ æä¾›çš„ä»£ç ç‰‡æ®µ) ===
    print("Reading Baseline Data...")
    ref_bers = []
    if os.path.exists(baseline_csv_path):
        try:
            with open(baseline_csv_path, 'r', newline='') as f:
                reader = csv.DictReader(f)
                baseline_data = {float(row['snr_db']): float(row['baseline_ber']) for row in reader}
                for snr in snr_range:
                    ref_bers.append(baseline_data.get(snr, 0.0))
        except Exception as e:
            print(f"Error reading CSV: {e}")
    else:
        print(f"Warning: Baseline file not found at {baseline_csv_path}")

    # === 5. ç»˜å›¾ä¸ä¿å­˜ ===
    save_and_plot(snr_range, model_bers, ref_bers, save_dir)